---
title: "Questão 7"
output:
  pdf_document:
    fig_crop: no
fontsize: 10pt
sansfont: Times
documentclass: article
geometry: 
 - a4paper
 - textwidth=18cm
 - textheight=21cm
header-includes:
  - \usepackage[utf8]{inputenc}
  - \usepackage[brazil, english, portuguese]{babel}
  - \usepackage[utf8]{inputenc}
  - \usepackage[T1]{fontenc}
  - \usepackage[fixlanguage]{babelbib}
  - \usepackage{times}

  - \usepackage{graphicx}
  - \usepackage{wrapfig}
  - \usepackage{pdfpages}
  
  - \usepackage{amsfonts}
  - \usepackage{amssymb}
  - \usepackage{amsmath}
  
  - \usepackage{fancyhdr}
  - \usepackage{subcaption}
  - \usepackage{booktabs}
  - \usepackage{caption}
  - \usepackage{float}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, 
  message = FALSE,
  warning = FALSE,
  tidy.opts = list(width.cutoff = 60),
  tidy = TRUE,
  digits=3
  )
options(
  OutDec = ",", 
  knitr.table.format = "latex", 
  xtable.comment = FALSE
  )
ggplot2::theme_set(ggplot2::theme_bw())
```

```{r}
library(tidyverse)
library(magrittr)
library(gridExtra)
library(corrplot)
library(ggfortify)
library(broom)
library(kableExtra)
library(readxl)
library(knitr)
library(formattable)
source("../diag_norm.R")
source("../envel_norm.R")
source("../norm_diag.R")
source("../anainflu_norm.R")
source("../cook_hat.R")
source("../estimate_table.R")
source("../model_measures.R")
```

# Introdução

Um estudo realizado na Faculdade de Odontologia da Universidade de São Paulo tinha como objetivo comprar duas escovas de dente (convencional e monobloco) com respeito à redução de um índice de placa bacteriana. De um total de 32 crianças foram coletados os índices de placa bacteriana (IPB) antes e depois da escovação. Cada criança foi submetido a 4 tratamentos (escova convencional com dentifrício, escova convencional sem dentifrício,escova monobloco com dentifrício, escova monobloco sem dentifrício), com espaçamento de 1 semana entre eles para eliminar possíveis efeito residuais.

Nosso objetio é comparar os quatro grupos formados pelas combinações dos fatores escova e dentifrício, assumindo que as observações não são correlacionadas e são homecadásticas, e determinar o grupo com melhor desemprenho. Para isso serão proposto modelos com duas variáveis respostas diferentes uma é $\frac{IPB\space depois}{IPB\space antes}$ (será denotada no resto do relatório como Razão A) e a outra é $\frac{IPB\space depois - IPB\space antes}{IPB\space antes}$ (será denotada no resto do relatório como Razão B). Para ambas quanto menor o seu valor melhor o desempenho da escovação. Ambas as variáveis respostas serão modeladas pelas variáveis explicativas tipo de escova e uso do dentrifício. A variável dentrifício será codificida da forma: 1 - uso de dentrifíco; 0 - sem uso de dentrifício.

Para tal análises será usada a metodologia dos modelos lineares homocedásticos, metodologias de verificação da qualidade do ajuste e comparação de modelos apropriado, veja Azevedo (2019). Todas as análises serão feitas com auxílio computacional do R.

# Análise Descritiva

```{r}
escovadf <- read_excel("Sef1999REG.xls", sheet = 4) %>%
  filter(antes != 0) %>% 
  mutate(razao12 = depois/antes, razao13 = (depois - antes)/antes,
         dentrificio = factor(dentrificio), escova = factor(escova))
```

Primeiramente devido a natureza da variável resposta duas observações tiveram que ser removidas do grupo, a do indivíduo 26 no dia 2 e a do indivíduo 24 também no dia 2, pois seus valores valores de IPB antes são iguais a zero e consequemente a variável resposta não é um número. O ideal seria contatar o pesquisador para conversar sobre esses casos e decidir o que fazer, mas como não é possível tivemos que tomar essa ação.

Em ambas as variáveis respostas, Razão A e Razão B, notamos através dos boxplots das figuras \ref{fig:boxA} e \ref{fig:boxB} e das tabelas \ref{tab:medA} e \ref{tab:medB} que a escova convencional parece performar melhor que a monobloco. Também observamos que a escovação com dentrifício apresenta um melhor resultado do que sem. Os boxplots das figuras \ref{fig:boxA} e \ref{fig:boxB} também sugerem uma assimetria na distribuição dos dados, que não é ideal em um modelo linear normal.

```{r, fig.cap="\\label{fig:boxA} Boxplot para a Razão A pelo tipo de escova e pelo uso de dentrifício.", fig.height=3.5}
escovadf %>% ggplot(aes(y = razao12, x = escova, fill = dentrificio)) + geom_boxplot() +
  scale_fill_grey(start = 0.4, end = 1) + 
  labs(x = "Tipo de escova", y = "Razão A", fill = "Dentrifício")
```

```{r}
escovadf %>% group_by(escova, dentrificio) %>%
  summarise(media = mean(razao12), dp = sd(razao12), cv = dp/media) %>%
  ungroup() %>% mutate_if(is.numeric, funs(round(.,4))) %>%
  mutate(cv = percent(cv)) %>%
  set_colnames(c("Escova", "Dentrifício", "Média", "Desvio Padrão", "Coeficiente de Variação")) %>% 
  kable("latex", booktabs = T, caption = "\\label{tab:medA}Medidas descritivas para a Razão A.") %>%
  kable_styling(font_size = 10)
```


```{r, fig.cap="\\label{fig:boxB} Boxplot para a Razão B pelo tipo de escova e pelo uso de dentrifício.", fig.height=3.5}
escovadf %>% ggplot(aes(y = razao13, x = escova, fill = dentrificio)) + geom_boxplot() +
  scale_fill_grey(start = 0.4, end = 1) + 
  labs(x = "Tipo de escova", y = "Razão B")
```

```{r}
escovadf %>% group_by(escova, dentrificio) %>%
  summarise(media = mean(razao13), dp = sd(razao13), cv = abs(dp/media)) %>%
  ungroup() %>% mutate_if(is.numeric, funs(round(.,4))) %>%
  mutate(cv = percent(cv)) %>%
  set_colnames(c("Escova", "Dentrifício", "Média", "Desvio Padrão", "Coeficiente de Variação")) %>% 
  kable("latex", booktabs = T, caption = "\\label{tab:medB}Medidas descritivas para a Razão B.") %>%
  kable_styling(font_size = 10)
```

# Análise Inferencial

Iremos primeiramente ajustar dois modelos lineares homecedásticos, o para a Razão A será chamado de Modelo A e o para a Razão B será chamado de Modelo B. Em ambos consideraremos as duas variáveis respostas e a sua interação. Os modelos serão ajustados segundo o método dos mínimos quadrados ordinários e a significância de casa parâmetro será testada a partir de vários testes, veja Azevedo(2019).

Para ambos os modelos teremos a mesma equação do modelo. Seja $Y_{ijk}$ a razão da k-ésima criançca para o tipo de escova i = (convencional, monobloco) e para o uso de dentrifíco j = (0,1). Temos o seguinte modelo:
$$Y_{ijk} = \mu + \beta_{0i} + \beta_{1j} + \beta_{0i}\beta_{1j} + \varepsilon_{ijk}$$
onde $\mu$ é o valor esperado de $Y_{ijk}$ para quando a criança usar a escova tradicional e não usar dentrifíco, $\beta_{0convencional} = 0$ e $\beta_{10} = 0$ pois estamos usando cassela de referência, $\beta_{0tradicional}$ é o efeito da criança usar escova tradicional na média, $\beta_{11}$ é o efeito do uso do dentrifíco e $\beta_{0i}\beta_{1j}$ é o efeito de interação das duas variáveis. A parte aleatório do modelo é dada por $\varepsilon_{ijk} \stackrel{\text{i.i.d}}{\sim} N(0,\sigma^2)$.

Os modelos são válido sobre as seguintes suposições: (i) $\varepsilon_{ijk} \stackrel{\text{i.i.d}}{\sim} N(0,\sigma^2)$; (ii) as observações são independentes; (iii) e a variância é constante.

Os modelos foram ajustado segundo o método dos mínimos quadrados ordinários e a significância de seus parâmetros fo determinada a partir de um teste de hipótese utilizando as estatística t. O resultado dos ajuste se encontra na tabela \ref{tab:parA} e \ref{tab:parA}, podemos notar que ambas praticamente só o $\mu$ é significante para o model. O $\beta_{11}$ pode ser considerado significátivo dependendo do nível de confiança e pelas análises descritivas isso parece ser plausível. Para entender mais de quais fatores são significantes fizemos uma análise de covariância. Observando o resultado desses testes nas tabelas \ref{tab:anovaA} e \ref{tab:anovaB} chegamos a conlusão que o uso de dentrifício afeta o modelo.

```{r}
escova.model.12 <- escovadf %>% lm(razao12 ~ escova*dentrificio,.)
```

```{r}
escova.model.13 <- escovadf %>% lm(razao13 ~ escova*dentrificio,.)
```

```{r}
tb12 <- escova.model.12 %>% estimate_tibble() %>% 
  kable("latex", booktabs = T, caption = "\\label{tab:parA}Estimativa para os parâmetros do modelo A") %>%
  kable_styling(font_size = 10)
```

\begin{table}[t]

\caption{\label{tab:}\label{tab:parA}Estimativa para os parâmetros do modelo A}
\centering
\fontsize{10}{12}\selectfont
\begin{tabular}{lrrlrl}
\toprule
Termo & Estimativa & Erro Padrão & IC (95\%) & Estatística t & p-valor\\
\midrule
$\mu$ & 0,695 & 0,042 & [ 0,612 ; 0,777 ] & 16,520 & < 0.001\\
$\beta_{0monobloco}$ & 0,032 & 0,060 & [ -0,085 ; 0,15 ] & 0,542 & 0,589\\
$\beta_{11}$ & -0,112 & 0,059 & [ -0,229 ; 0,005 ] & -1,883 & 0,062\\
$\beta_{0monobloco}\beta_{11}$ & 0,026 & 0,085 & [ -0,14 ; 0,192 ] & 0,307 & 0,76\\
\bottomrule
\end{tabular}
\end{table}

```{r}
tb13 <- escova.model.13 %>% estimate_tibble() %>% 
  kable("latex", booktabs = T, caption = "\\label{tab:parB}Estimativa para os parâmetros do modelo B") %>%
  kable_styling(font_size = 10)
```

\begin{table}[t]

\caption{\label{tab:}\label{tab:parB}Estimativa para os parâmetros do modelo B}
\centering
\fontsize{10}{12}\selectfont
\begin{tabular}{lrrlrl}
\toprule
Termo & Estimativa & Erro Padrão & IC (95\%) & Estatística t & p-valor\\
\midrule
$\mu$ & -0,305 & 0,042 & [ -0,388 ; -0,223 ] & -7,261 & < 0.001\\
$\beta_{0monobloco}$ & 0,032 & 0,060 & [ -0,085 ; 0,15 ] & 0,542 & 0,589\\
$\beta_{11}$ & -0,112 & 0,059 & [ -0,229 ; 0,005 ] & -1,883 & 0,062\\
$\beta_{0monobloco}\beta_{11}$ & 0,026 & 0,085 & [ -0,14 ; 0,192 ] & 0,307 & 0,76\\
\bottomrule
\end{tabular}
\end{table}

```{r}
anova12 <- anova(escova.model.12) %>% broom::tidy() %>% mutate_if(is.numeric, funs(round(.,4))) %>%
  magrittr::set_colnames(c("Fonte de variação", "Graus de liberdade",
                           "Soma de quadrados", "Quadrados Médios",
                           "Estatística","p-valor")) %>%
  knitr::kable("latex", caption = "\\label{tab:anovaA}Análise de convariância para o modelo A", booktabs = T) %>%
  kableExtra::kable_styling(font_size = 10)
```

\begin{table}[t]

\caption{\label{tab:}\label{tab:anovaA}Análise de convariância para o modelo A}
\centering
\fontsize{10}{12}\selectfont
\begin{tabular}{lrrrrr}
\toprule
Fonte de variação & Graus de liberdade & Soma de quadrados & Quadrados Médios & Estatística & p-valor\\
\midrule
$\beta_{0i}$ & 1 & 0,0652 & 0,0652 & 1,1520 & 0,2853\\
$\beta_{1j}$ & 1 & 0,3100 & 0,3100 & 5,4786 & 0,0209\\
$\beta_{0i}\beta_{1j}$ & 1 & 0,0053 & 0,0053 & 0,0941 & 0,7596\\
Erro & 122 & 6,9029 & 0,0566 & NA & NA\\
\bottomrule
\end{tabular}
\end{table}

```{r}
anova13 <- anova(escova.model.13) %>% broom::tidy() %>% mutate_if(is.numeric, funs(round(.,4))) %>%
  magrittr::set_colnames(c("Fonte de variação", "Graus de liberdade",
                           "Soma de quadrados", "Quadrados Médios",
                           "Estatística","p-valor")) %>%
  knitr::kable("latex", caption = "\\label{tab:anovaB}Análise de convariância para o modelo B", booktabs = T) %>%
  kableExtra::kable_styling(font_size = 10)
```

\begin{table}[t]

\caption{\label{tab:}\label{tab:anovaB}Análise de convariância para o modelo B}
\centering
\fontsize{10}{12}\selectfont
\begin{tabular}{lrrrrr}
\toprule
Fonte de variação & Graus de liberdade & Soma de quadrados & Quadrados Médios & Estatística & p-valor\\
\midrule
$\beta_{0i}$ & 1 & 0,0652 & 0,0652 & 1,1520 & 0,2853\\
$\beta_{1j}$ & 1 & 0,3100 & 0,3100 & 5,4786 & 0,0209\\
$\beta_{0i}\beta_{1j}$ & 1 & 0,0053 & 0,0053 & 0,0941 & 0,7596\\
Erro & 122 & 6,9029 & 0,0566 & NA & NA\\
\bottomrule
\end{tabular}
\end{table}

Para ambos os modelos as análises de resíduos, figuras \ref{fig:diagA} e \ref{fig:diagB} indicaram quebra das suposições. O gráficos dos resíduos pelos valores ajustados indicam a presença de Heteroscedasticidade, os histogramas e os gráficos quantis-quantis indicam a ausencência de normalidade devido a forte assimetria. Apenas a suposição de indepêndencia parece se manter. 

```{r, fig.cap="\\label{fig:diagA} Diagnóstico do modelo A", fig.height=3.5}
normal_diag(escova.model.12)
```

```{r, fig.cap="\\label{fig:diagB} Diagnóstico do modelo B", fig.height=3.5}
normal_diag(escova.model.13)
```

Devido ao mal ajuste dos modelos propostos, proporemos dois novos modelos que irão considerar apenas o fator do uso do dentrífico. Os modelos reduzidos serão dados por:
$$Y_{jk} = \mu + \beta_j + \varepsilon_{jk}$$
onde $\mu$ é o valor esperado na variável resposta quando a criança escova sem dentrifíco, $\beta_0 =0$ por adotarmos cassela de referência e $\beta_1$ é o efeito esperado para quando a criança escova com dentrifíco. Aind temos as mesmas suposições: (i) $\varepsilon_{ij} \stackrel{\text{i.i.d}}{\sim} N(0,\sigma^2)$; (ii) as observações são independentes; (iii) e a variância é constante.

As novas estimativas podem ser vistas nas tabelas \ref{tab:parAr} e \ref{tab:parBr}, dessa vez todos os seu parâmetros são significantes. No diagnóstico do modelo, nas figuras \ref{fig:diagAr} e \ref{fig:diagBr}, podemos novamente rejeitar a suposição de normalidade, embora o problema de heterocedasticidade tenha sido resolvido ou pelo menos amenizado. Em relação aos pontos influentes ou alavanca, para ambos os modelos nenhum ponto se confirmou. Na medida H nenhum dos pontos passam do limiar e os pontos que se destacan na distância de cook na influênciam muito nas estatisticas do modelo e não mudam a conclusão.

```{r}
escova.model.12reduzido <- escovadf %>% lm(razao12 ~ dentrificio,.)
```

```{r}
escova.model.13reduzido <- escovadf %>% lm(razao13 ~ dentrificio,.)
```

```{r}
tb12R <- escova.model.12reduzido %>% estimate_tibble() %>% 
  kable("latex", booktabs = T, caption = "\\label{tab:parAr}Estimativa para os parâmetros do modelo A reduzido") %>%
  kable_styling(font_size = 10)
```

\begin{table}[t]

\caption{\label{tab:}\label{tab:parAr}Estimativa para os parâmetros do modelo A reduzido}
\centering
\fontsize{10}{12}\selectfont
\begin{tabular}{lrrlrl}
\toprule
Termo & Estimativa & Erro Padrão & IC (95\%) & Estatística t & p-valor\\
\midrule
$\mu$ & 0,711 & 0,030 & [ 0,652 ; 0,769 ] & 23,786 & < 0.001\\
$\beta_1$ & -0,099 & 0,042 & [ -0,182 ; -0,016 ] & -2,348 & 0,02\\
\bottomrule
\end{tabular}
\end{table}

```{r}
tb13R <- escova.model.13reduzido %>% estimate_tibble() %>% 
  kable("latex", booktabs = T, caption = "\\label{tab:parBr}Estimativa para os parâmetros do modelo B reduzido") %>%
  kable_styling(font_size = 10)
```

\begin{table}[t]

\caption{\label{tab:}\label{tab:parBr}Estimativa para os parâmetros do modelo B reduzido}
\centering
\fontsize{10}{12}\selectfont
\begin{tabular}{lrrlrl}
\toprule
Termo & Estimativa & Erro Padrão & IC (95\%) & Estatística t & p-valor\\
\midrule
$\mu$ & -0,289 & 0,030 & [ -0,348 ; -0,231 ] & -9,684 & < 0.001\\
$\beta_1$ & -0,099 & 0,042 & [ -0,182 ; -0,016 ] & -2,348 & 0,02\\
\bottomrule
\end{tabular}
\end{table}

```{r, fig.cap="\\label{fig:diagAr} Diagnóstico do modelo A reduzido", fig.height=3.5}
normal_diag(escova.model.12reduzido)
```

```{r, fig.cap="\\label{fig:diagBr} Diagnóstico do modelo B reduzido", fig.height=3.5}
normal_diag(escova.model.13reduzido)
```

```{r ,fig.cap="\\label{fig:infA}Análise de pontos influentes e alavancas para o modelo A reduzido", fig.height=3.5}
cook_hat(escova.model.12reduzido)
```

```{r ,fig.cap="\\label{fig:infB}Análise de pontos influentes e alavancas para o modelo B reduzido", fig.height=3.5}
cook_hat(escova.model.13reduzido)
```

Na comparação dos modelos os modelos A e B, e A e B reduzidos se mostraram praticamente identicos, como visto na tabela \ref{tab:comp}. Porém ao comparar os modelos reduzidos aos completo os modelos reduzidos parecem melhor.

```{r}
medidas <- cbind(model_measures(escova.model.12),model_measures(escova.model.13),
                 model_measures(escova.model.12reduzido),model_measures(escova.model.13reduzido)) %>%
  set_colnames(c("Modelo A", "Modelo B", "Modelo A Reduzido", "Modelo B Reduzido")) %>%
  kable("latex", caption = "\\label{tab:comp}Medidas de comparação do modelo.", booktabs = T) %>% kable_styling(font_size = 10)
medidas
```

# Conclusão
 
Todos os modelos ajustados não se mostraram apropriados, ou seja quebraram algumas das suposições necessárias. Devido a isso as estatísticas e portanto as conclusões sobre os dados podem estar erradas. Em nossa análise o tipo de escova se mostrou não significativo no modelo, porem a análise descritiva sugere um efeito do mesmo, talvez se usassemos de um modelo mais apropriado mais apropriado esse fator se provesse significativo.

Tabrabalhando com os modelos que temos em mão os modelos reduzidos parecem mais apropriados que os modelos completos e aparentemente quebram menos suposições. Considerando as análises de diagnóstico e as medidas de comparação os modelos reduzidos parecem uma melhor escolha. Os modelos não se mostram diferentes em relação a razão A e razão B, portanto escolhemo o modelo de mais fácil interpretabilidade, que ao nosso ver é a razão A. Pois nessa razão quanto mais perto de 0 mais efetivo foi a escovação e para razão B quanto mais perto de -1.


# Referências

Azevedo, C. L. N (2019). Notas de aula sobre Análise de regressão, http://www.ime.unicamp.br/~cnaber/Material_ME613_1S_2019.htm

Paula, G. A. (2013). Modelos de regressão com apoio computacional, versão pré-eliminar, https://www.ime.usp.br/~giapaula/texto_2013.pdf




